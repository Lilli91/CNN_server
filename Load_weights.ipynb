{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 38,
   "metadata": {
    "collapsed": false,
    "deletable": true,
    "editable": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "990\n",
      "(1980,)\n",
      "[1 1 2 ..., 1 2 1]\n",
      "[[ 0.  1.  0.  0.  0.  0.]\n",
      " [ 0.  1.  0.  0.  0.  0.]\n",
      " [ 0.  0.  1.  0.  0.  0.]\n",
      " ..., \n",
      " [ 0.  1.  0.  0.  0.  0.]\n",
      " [ 0.  0.  1.  0.  0.  0.]\n",
      " [ 0.  1.  0.  0.  0.  0.]]\n"
     ]
    }
   ],
   "source": [
    "import os\n",
    "os.environ[\"CUDA_VISIBLE_DEVICES\"] = \"1\"\n",
    "import keras\n",
    "from keras.layers import convolutional, Dense, Activation,pooling\n",
    "from keras.layers import Input, merge, Convolution2D, MaxPooling2D, UpSampling2D, Flatten, Dropout\n",
    "from keras.optimizers import Adam, SGD\n",
    "from keras.models import Sequential, Model\n",
    "from keras.callbacks import Callback, EarlyStopping, ModelCheckpoint, LearningRateScheduler\n",
    "from keras.regularizers import l2\n",
    "from keras import backend as K\n",
    "from keras.utils import np_utils\n",
    "import tensorflow as tf\n",
    "from keras.backend.tensorflow_backend import set_session\n",
    "import cPickle as pickle\n",
    "import scipy.io\n",
    "import numpy as np\n",
    "import h5py\n",
    "\n",
    "config = tf.ConfigProto()\n",
    "#config.gpu_options.per_process_gpu_memory_fraction = 1.0\n",
    "set_session(tf.Session(config=config))\n",
    "\n",
    "\n",
    "\n",
    "###################################### LOADING DATA ##############################\n",
    "\n",
    "### Create a dictionary that contains all the dictiories within each dataset (workspace) we want to load ###\n",
    "\n",
    "#Go to the data directory\n",
    "dataDir = \"/scratch/barbieri/DATA_CNN_networks/Data/\"\n",
    "Load_Data = {}  \n",
    "for i in range(0, len(os.listdir( dataDir ))):  \n",
    "    Load_Data[i] = {}  #Dictionary for a single workspace\n",
    "\n",
    "    \n",
    "### lOAD THE DATA STORING THEM IN A DICTIONARY ###\n",
    "i = 0\n",
    "for file in os.listdir( dataDir ):\n",
    "    Load_Data[i]['File'] =  scipy.io.loadmat( dataDir+file )\n",
    "    i = i+1\n",
    "\n",
    "    \n",
    "#### Define another dictionary for storing intensity curves and classes ### \n",
    "#From each dataset, the intensity curve and classes are extracted and stored in another dictionary\n",
    "DATA = {}\n",
    "N_of_file =len(os.listdir( dataDir ))\n",
    "for i in range(0, N_of_file):\n",
    "        DATA[i] = {}\n",
    "\n",
    "\n",
    "#### Fill the dictionary ###\n",
    "Ncell_classified = 200 #Number of classified cells per dataset\n",
    "for i in range(0, N_of_file):\n",
    "    #Decision array for each dataset\n",
    "    DATA[i]['decision'] = Load_Data[i]['File']['decisionlist']\n",
    "    #Size of the matrix to store intensity values\n",
    "    NumofData = len(Load_Data[i]['File']['RAWDATA'][0,0]['files'][0,0][0]['intensity'])\n",
    "    Int_curve_len = len(Load_Data[4]['File']['RAWDATA'][0,0]['files'][0,0][0]['intensity'][0][0])\n",
    "    #Empty matrix to store all the intensity values of all the cells\n",
    "    DATA[i]['intensity'] = np.zeros((Ncell_classified,  Int_curve_len ))\n",
    "    for k in range(0,Ncell_classified): #Only the first 200 were classified\n",
    "        DATA[i]['intensity'][k,:] = Load_Data[i]['File']['RAWDATA'][0,0]['files'][0,0][0]['intensity'][k][0,0:900] #copy the first 900 values\n",
    "\n",
    "        \n",
    "### Classes array: contain values from all the data ###\n",
    "Classes=[]\n",
    "for i in range( 0, N_of_file ):\n",
    "    Classes = np.append(Classes , DATA[i]['decision']).astype(int)\n",
    "\n",
    "    \n",
    "### Intensities matrix: contain values from all the data    \n",
    "NTot_Data = N_of_file*Ncell_classified\n",
    "Intensity = np.zeros((0, DATA[0]['intensity'].shape[1]))\n",
    "for i in range( 0, N_of_file ):\n",
    "    Intensity = np.append(Intensity, DATA[i]['intensity'][:,:], axis=0)\n",
    "\n",
    "    \n",
    "### Elimate intensity profiles with NaN values and corresponding classes ###\n",
    "nan_indices = np.where(np.isnan(Intensity))\n",
    "Intensity = np.delete(Intensity,nan_indices[0], axis = 0)\n",
    "Classes = np.delete(Classes,nan_indices[0], axis = 0)\n",
    "#Redefine the total number of data\n",
    "total = len(Intensity)\n",
    "\n",
    "# DUPLICATE Intensity profiles adding noise to the second group\n",
    "print(total)\n",
    "Intensity_more_curves_noise = np.zeros((2*total,  Int_curve_len ))\n",
    "Intensity_more_curves_noise[0:990,:] = Intensity\n",
    "Intensity_more_curves_noise[990:1980,:] = Intensity + np.random.randn(Int_curve_len)*0.01\n",
    "\n",
    "#Redefine the total number of data\n",
    "total = len(Intensity_more_curves_noise)\n",
    "\n",
    "\n",
    "#DUPLICATE CLASSES\n",
    "Classes = np.append(Classes, Classes)\n",
    "print(Classes.shape)\n",
    "\n",
    "\n",
    "### Downsampling\n",
    "data1 = Intensity_more_curves_noise[:,0:768]\n",
    "step = 3\n",
    "#256 points\n",
    "data_downsampl = data1[:,::step]\n",
    "#Redefine len of the Intensity curves:\n",
    "Int_profile_len = len(data_downsampl[0])\n",
    "\n",
    "#Check if there are typo errors for the classes (we only have 6 classes going from 0 to 5)\n",
    "for i in range(len(Classes)):\n",
    "    if Classes[i] > 5:\n",
    "        print(i)\n",
    "        \n",
    "        \n",
    "### Distribute all values randomly ###\n",
    "randseq = np.random.choice(np.arange(0,total),total,replace=False)\n",
    "#Data randomly organized\n",
    "data_downsampl = data_downsampl[randseq,:]\n",
    "Classes = Classes[randseq]\n",
    "Classes_to_categorical = np_utils.to_categorical(Classes)\n",
    "\n",
    "######################### load file - training data ####################\n",
    "train_dt = data_downsampl[0:800,:]\n",
    "train_cl = Classes_to_categorical[0:800]\n",
    "X = train_dt  \n",
    "y = train_cl \n",
    "N_train_cell = len(train_dt)\n",
    "# process the data to fit in a keras CNN properly\n",
    "# input data needs to be (N, C, X, Y) - shaped where\n",
    "# N - number of samples\n",
    "# C - number of channels per sample\n",
    "# (X, Y) - sample size\n",
    "\n",
    "X = X.reshape((N_train_cell, Int_profile_len,1, 1))\n",
    "\n",
    "\n",
    "######################### load file - testing data ####################\n",
    "#Define variables \n",
    "N_test_cell = total - N_train_cell\n",
    "#Matrix for intensity values\n",
    "test_dt = np.zeros((N_test_cell,Int_profile_len))\n",
    "#Use as testing data the last N_test_cell values within the total \n",
    "test_dt[:,:]= data_downsampl[N_train_cell:total]\n",
    "#Same process for the associated classes\n",
    "test_cl = Classes[N_train_cell:total]\n",
    "print(test_cl)\n",
    "test_cl_category = Classes_to_categorical[N_train_cell:total]\n",
    "print(test_cl_category)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 39,
   "metadata": {
    "collapsed": false,
    "deletable": true,
    "editable": true
   },
   "outputs": [],
   "source": [
    "# How to load and use weights from a checkpoint\n",
    "\n",
    "# define a CNN\n",
    "# see http://keras.io for API reference\n",
    "\n",
    "cnn = Sequential()\n",
    "cnn.add(Convolution2D(64, 3, 1,border_mode=\"same\",activation=\"relu\",input_shape=(Int_profile_len,1, 1)))\n",
    "cnn.add(Convolution2D(64, 3, 1, border_mode=\"same\", activation=\"relu\"))\n",
    "cnn.add(MaxPooling2D(pool_size=(2,1)))\n",
    "\n",
    "cnn.add(Convolution2D(128, 3, 1, border_mode=\"same\", activation=\"relu\"))\n",
    "cnn.add(Convolution2D(128, 3, 1, border_mode=\"same\", activation=\"relu\"))\n",
    "cnn.add(Convolution2D(128, 3, 1, border_mode=\"same\", activation=\"relu\"))\n",
    "cnn.add(MaxPooling2D(pool_size=(2,1)))\n",
    "    \n",
    "cnn.add(Convolution2D(256, 3, 1, border_mode=\"same\", activation=\"relu\"))\n",
    "cnn.add(Convolution2D(256, 3, 1, border_mode=\"same\", activation=\"relu\"))\n",
    "cnn.add(Convolution2D(256, 3, 1, border_mode=\"same\", activation=\"relu\"))\n",
    "cnn.add(MaxPooling2D(pool_size=(2,1)))\n",
    "    \n",
    "cnn.add(Flatten())\n",
    "cnn.add(Dense(1024, activation=\"relu\"))\n",
    "cnn.add(Dropout(0.5))\n",
    "cnn.add(Dense(6, activation=\"softmax\"))\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 56,
   "metadata": {
    "collapsed": false,
    "deletable": true,
    "editable": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Created model and loaded weights from file\n"
     ]
    }
   ],
   "source": [
    "# load weights\n",
    "cnn.load_weights(\"/scratch/barbieri/DATA_CNN_networks/Different_decay_val/iteration1/06_06_2017_Noise1800data_weights.best_DecayValue0.001Iter0.hdf5\")\n",
    "# Compile model (required to make predictions)\n",
    "cnn.compile(loss=\"categorical_crossentropy\", optimizer=Adam(lr=0.0001, beta_1=0.9, beta_2=0.999, epsilon=1e-08, decay=0.001), metrics=['accuracy'])\n",
    "print(\"Created model and loaded weights from file\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 55,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "ename": "AttributeError",
     "evalue": "'NoneType' object has no attribute 'shape'",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mAttributeError\u001b[0m                            Traceback (most recent call last)",
      "\u001b[0;32m<ipython-input-55-f4d4f45285be>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m()\u001b[0m\n\u001b[0;32m----> 1\u001b[0;31m \u001b[0;32mprint\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0ma\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mshape\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m",
      "\u001b[0;31mAttributeError\u001b[0m: 'NoneType' object has no attribute 'shape'"
     ]
    }
   ],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 58,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "ename": "ResourceExhaustedError",
     "evalue": "OOM when allocating tensor with shape[8192,1024]\n\t [[Node: mul_109 = Mul[T=DT_FLOAT, _device=\"/job:localhost/replica:0/task:0/gpu:0\"](Variable_13/read, Variable_53/read)]]\n\t [[Node: mul_13/_135 = _Recv[client_terminated=false, recv_device=\"/job:localhost/replica:0/task:0/cpu:0\", send_device=\"/job:localhost/replica:0/task:0/gpu:0\", send_device_incarnation=1, tensor_name=\"edge_1764_mul_13\", tensor_type=DT_FLOAT, _device=\"/job:localhost/replica:0/task:0/cpu:0\"]()]]\n\nCaused by op u'mul_109', defined at:\n  File \"/usr/lib64/python2.7/runpy.py\", line 162, in _run_module_as_main\n    \"__main__\", fname, loader, pkg_name)\n  File \"/usr/lib64/python2.7/runpy.py\", line 72, in _run_code\n    exec code in run_globals\n  File \"/t1-home/molimm2/dwaithe/.local/lib/python2.7/site-packages/ipykernel/__main__.py\", line 3, in <module>\n    app.launch_new_instance()\n  File \"/home/molimm2/dwaithe/.local/lib/python2.7/site-packages/traitlets/config/application.py\", line 658, in launch_instance\n    app.start()\n  File \"/home/molimm2/dwaithe/.local/lib/python2.7/site-packages/ipykernel/kernelapp.py\", line 474, in start\n    ioloop.IOLoop.instance().start()\n  File \"/home/molimm2/dwaithe/.local/lib/python2.7/site-packages/zmq/eventloop/ioloop.py\", line 177, in start\n    super(ZMQIOLoop, self).start()\n  File \"/home/molimm2/dwaithe/.local/lib/python2.7/site-packages/tornado/ioloop.py\", line 887, in start\n    handler_func(fd_obj, events)\n  File \"/home/molimm2/dwaithe/.local/lib/python2.7/site-packages/tornado/stack_context.py\", line 275, in null_wrapper\n    return fn(*args, **kwargs)\n  File \"/home/molimm2/dwaithe/.local/lib/python2.7/site-packages/zmq/eventloop/zmqstream.py\", line 440, in _handle_events\n    self._handle_recv()\n  File \"/home/molimm2/dwaithe/.local/lib/python2.7/site-packages/zmq/eventloop/zmqstream.py\", line 472, in _handle_recv\n    self._run_callback(callback, msg)\n  File \"/home/molimm2/dwaithe/.local/lib/python2.7/site-packages/zmq/eventloop/zmqstream.py\", line 414, in _run_callback\n    callback(*args, **kwargs)\n  File \"/home/molimm2/dwaithe/.local/lib/python2.7/site-packages/tornado/stack_context.py\", line 275, in null_wrapper\n    return fn(*args, **kwargs)\n  File \"/home/molimm2/dwaithe/.local/lib/python2.7/site-packages/ipykernel/kernelbase.py\", line 276, in dispatcher\n    return self.dispatch_shell(stream, msg)\n  File \"/home/molimm2/dwaithe/.local/lib/python2.7/site-packages/ipykernel/kernelbase.py\", line 228, in dispatch_shell\n    handler(stream, idents, msg)\n  File \"/home/molimm2/dwaithe/.local/lib/python2.7/site-packages/ipykernel/kernelbase.py\", line 390, in execute_request\n    user_expressions, allow_stdin)\n  File \"/home/molimm2/dwaithe/.local/lib/python2.7/site-packages/ipykernel/ipkernel.py\", line 196, in do_execute\n    res = shell.run_cell(code, store_history=store_history, silent=silent)\n  File \"/home/molimm2/dwaithe/.local/lib/python2.7/site-packages/ipykernel/zmqshell.py\", line 501, in run_cell\n    return super(ZMQInteractiveShell, self).run_cell(*args, **kwargs)\n  File \"/home/molimm2/dwaithe/.local/lib/python2.7/site-packages/IPython/core/interactiveshell.py\", line 2717, in run_cell\n    interactivity=interactivity, compiler=compiler, result=result)\n  File \"/home/molimm2/dwaithe/.local/lib/python2.7/site-packages/IPython/core/interactiveshell.py\", line 2821, in run_ast_nodes\n    if self.run_code(code, result):\n  File \"/home/molimm2/dwaithe/.local/lib/python2.7/site-packages/IPython/core/interactiveshell.py\", line 2881, in run_code\n    exec(code_obj, self.user_global_ns, self.user_ns)\n  File \"<ipython-input-57-67f2c0cccadb>\", line 1, in <module>\n    results = cnn.fit(X, y, nb_epoch=200, batch_size=100,verbose=0)\n  File \"/home/molimm2/dwaithe/.local/lib/python2.7/site-packages/keras/models.py\", line 664, in fit\n    sample_weight=sample_weight)\n  File \"/home/molimm2/dwaithe/.local/lib/python2.7/site-packages/keras/engine/training.py\", line 1115, in fit\n    self._make_train_function()\n  File \"/home/molimm2/dwaithe/.local/lib/python2.7/site-packages/keras/engine/training.py\", line 713, in _make_train_function\n    self.total_loss)\n  File \"/home/molimm2/dwaithe/.local/lib/python2.7/site-packages/keras/optimizers.py\", line 392, in get_updates\n    v_t = (self.beta_2 * v) + (1. - self.beta_2) * K.square(g)\n  File \"/home/molimm2/dwaithe/.local/lib/python2.7/site-packages/tensorflow/python/ops/variables.py\", line 690, in _run_op\n    return getattr(ops.Tensor, operator)(a._AsTensor(), *args)\n  File \"/home/molimm2/dwaithe/.local/lib/python2.7/site-packages/tensorflow/python/ops/math_ops.py\", line 814, in binary_op_wrapper\n    return func(x, y, name=name)\n  File \"/home/molimm2/dwaithe/.local/lib/python2.7/site-packages/tensorflow/python/ops/math_ops.py\", line 987, in _mul_dispatch\n    return gen_math_ops.mul(x, y, name=name)\n  File \"/home/molimm2/dwaithe/.local/lib/python2.7/site-packages/tensorflow/python/ops/gen_math_ops.py\", line 1613, in mul\n    result = _op_def_lib.apply_op(\"Mul\", x=x, y=y, name=name)\n  File \"/home/molimm2/dwaithe/.local/lib/python2.7/site-packages/tensorflow/python/framework/op_def_library.py\", line 759, in apply_op\n    op_def=op_def)\n  File \"/home/molimm2/dwaithe/.local/lib/python2.7/site-packages/tensorflow/python/framework/ops.py\", line 2240, in create_op\n    original_op=self._default_original_op, op_def=op_def)\n  File \"/home/molimm2/dwaithe/.local/lib/python2.7/site-packages/tensorflow/python/framework/ops.py\", line 1128, in __init__\n    self._traceback = _extract_stack()\n\nResourceExhaustedError (see above for traceback): OOM when allocating tensor with shape[8192,1024]\n\t [[Node: mul_109 = Mul[T=DT_FLOAT, _device=\"/job:localhost/replica:0/task:0/gpu:0\"](Variable_13/read, Variable_53/read)]]\n\t [[Node: mul_13/_135 = _Recv[client_terminated=false, recv_device=\"/job:localhost/replica:0/task:0/cpu:0\", send_device=\"/job:localhost/replica:0/task:0/gpu:0\", send_device_incarnation=1, tensor_name=\"edge_1764_mul_13\", tensor_type=DT_FLOAT, _device=\"/job:localhost/replica:0/task:0/cpu:0\"]()]]\n",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mResourceExhaustedError\u001b[0m                    Traceback (most recent call last)",
      "\u001b[0;32m<ipython-input-58-ba176644963e>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m()\u001b[0m\n\u001b[0;32m----> 1\u001b[0;31m \u001b[0mresults\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mcnn\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mfit\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mX\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0my\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mnb_epoch\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;36m200\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mbatch_size\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;36m100\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0mverbose\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;36m0\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m      2\u001b[0m     \u001b[0;31m#Evaluation code which makes prediction\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      3\u001b[0m \u001b[0;31m#out = cnn.predict(test_dt.reshape((N_test_cell, Int_profile_len,1, 1)))\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      4\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/home/molimm2/dwaithe/.local/lib/python2.7/site-packages/keras/models.pyc\u001b[0m in \u001b[0;36mfit\u001b[0;34m(self, x, y, batch_size, nb_epoch, verbose, callbacks, validation_split, validation_data, shuffle, class_weight, sample_weight, **kwargs)\u001b[0m\n\u001b[1;32m    662\u001b[0m                               \u001b[0mshuffle\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mshuffle\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    663\u001b[0m                               \u001b[0mclass_weight\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mclass_weight\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 664\u001b[0;31m                               sample_weight=sample_weight)\n\u001b[0m\u001b[1;32m    665\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    666\u001b[0m     def evaluate(self, x, y, batch_size=32, verbose=1,\n",
      "\u001b[0;32m/home/molimm2/dwaithe/.local/lib/python2.7/site-packages/keras/engine/training.pyc\u001b[0m in \u001b[0;36mfit\u001b[0;34m(self, x, y, batch_size, nb_epoch, verbose, callbacks, validation_split, validation_data, shuffle, class_weight, sample_weight, initial_epoch)\u001b[0m\n\u001b[1;32m   1141\u001b[0m                               \u001b[0mval_f\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mval_f\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mval_ins\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mval_ins\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mshuffle\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mshuffle\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1142\u001b[0m                               \u001b[0mcallback_metrics\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mcallback_metrics\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 1143\u001b[0;31m                               initial_epoch=initial_epoch)\n\u001b[0m\u001b[1;32m   1144\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1145\u001b[0m     \u001b[0;32mdef\u001b[0m \u001b[0mevaluate\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mx\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0my\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mbatch_size\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;36m32\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mverbose\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;36m1\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0msample_weight\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mNone\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/home/molimm2/dwaithe/.local/lib/python2.7/site-packages/keras/engine/training.pyc\u001b[0m in \u001b[0;36m_fit_loop\u001b[0;34m(self, f, ins, out_labels, batch_size, nb_epoch, verbose, callbacks, val_f, val_ins, shuffle, callback_metrics, initial_epoch)\u001b[0m\n\u001b[1;32m    841\u001b[0m                 \u001b[0mbatch_logs\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;34m'size'\u001b[0m\u001b[0;34m]\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mlen\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mbatch_ids\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    842\u001b[0m                 \u001b[0mcallbacks\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mon_batch_begin\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mbatch_index\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mbatch_logs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 843\u001b[0;31m                 \u001b[0mouts\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mf\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mins_batch\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    844\u001b[0m                 \u001b[0;32mif\u001b[0m \u001b[0;32mnot\u001b[0m \u001b[0misinstance\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mouts\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mlist\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    845\u001b[0m                     \u001b[0mouts\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;34m[\u001b[0m\u001b[0mouts\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/home/molimm2/dwaithe/.local/lib/python2.7/site-packages/keras/backend/tensorflow_backend.pyc\u001b[0m in \u001b[0;36m__call__\u001b[0;34m(self, inputs)\u001b[0m\n\u001b[1;32m   1601\u001b[0m         \u001b[0msession\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mget_session\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1602\u001b[0m         updated = session.run(self.outputs + [self.updates_op],\n\u001b[0;32m-> 1603\u001b[0;31m                               feed_dict=feed_dict)\n\u001b[0m\u001b[1;32m   1604\u001b[0m         \u001b[0;32mreturn\u001b[0m \u001b[0mupdated\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0mlen\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0moutputs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1605\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/home/molimm2/dwaithe/.local/lib/python2.7/site-packages/tensorflow/python/client/session.pyc\u001b[0m in \u001b[0;36mrun\u001b[0;34m(self, fetches, feed_dict, options, run_metadata)\u001b[0m\n\u001b[1;32m    764\u001b[0m     \u001b[0;32mtry\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    765\u001b[0m       result = self._run(None, fetches, feed_dict, options_ptr,\n\u001b[0;32m--> 766\u001b[0;31m                          run_metadata_ptr)\n\u001b[0m\u001b[1;32m    767\u001b[0m       \u001b[0;32mif\u001b[0m \u001b[0mrun_metadata\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    768\u001b[0m         \u001b[0mproto_data\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mtf_session\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mTF_GetBuffer\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mrun_metadata_ptr\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/home/molimm2/dwaithe/.local/lib/python2.7/site-packages/tensorflow/python/client/session.pyc\u001b[0m in \u001b[0;36m_run\u001b[0;34m(self, handle, fetches, feed_dict, options, run_metadata)\u001b[0m\n\u001b[1;32m    962\u001b[0m     \u001b[0;32mif\u001b[0m \u001b[0mfinal_fetches\u001b[0m \u001b[0;32mor\u001b[0m \u001b[0mfinal_targets\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    963\u001b[0m       results = self._do_run(handle, final_targets, final_fetches,\n\u001b[0;32m--> 964\u001b[0;31m                              feed_dict_string, options, run_metadata)\n\u001b[0m\u001b[1;32m    965\u001b[0m     \u001b[0;32melse\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    966\u001b[0m       \u001b[0mresults\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;34m[\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/home/molimm2/dwaithe/.local/lib/python2.7/site-packages/tensorflow/python/client/session.pyc\u001b[0m in \u001b[0;36m_do_run\u001b[0;34m(self, handle, target_list, fetch_list, feed_dict, options, run_metadata)\u001b[0m\n\u001b[1;32m   1012\u001b[0m     \u001b[0;32mif\u001b[0m \u001b[0mhandle\u001b[0m \u001b[0;32mis\u001b[0m \u001b[0mNone\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1013\u001b[0m       return self._do_call(_run_fn, self._session, feed_dict, fetch_list,\n\u001b[0;32m-> 1014\u001b[0;31m                            target_list, options, run_metadata)\n\u001b[0m\u001b[1;32m   1015\u001b[0m     \u001b[0;32melse\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1016\u001b[0m       return self._do_call(_prun_fn, self._session, handle, feed_dict,\n",
      "\u001b[0;32m/home/molimm2/dwaithe/.local/lib/python2.7/site-packages/tensorflow/python/client/session.pyc\u001b[0m in \u001b[0;36m_do_call\u001b[0;34m(self, fn, *args)\u001b[0m\n\u001b[1;32m   1032\u001b[0m         \u001b[0;32mexcept\u001b[0m \u001b[0mKeyError\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1033\u001b[0m           \u001b[0;32mpass\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 1034\u001b[0;31m       \u001b[0;32mraise\u001b[0m \u001b[0mtype\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0me\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mnode_def\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mop\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mmessage\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m   1035\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1036\u001b[0m   \u001b[0;32mdef\u001b[0m \u001b[0m_extend_graph\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;31mResourceExhaustedError\u001b[0m: OOM when allocating tensor with shape[8192,1024]\n\t [[Node: mul_109 = Mul[T=DT_FLOAT, _device=\"/job:localhost/replica:0/task:0/gpu:0\"](Variable_13/read, Variable_53/read)]]\n\t [[Node: mul_13/_135 = _Recv[client_terminated=false, recv_device=\"/job:localhost/replica:0/task:0/cpu:0\", send_device=\"/job:localhost/replica:0/task:0/gpu:0\", send_device_incarnation=1, tensor_name=\"edge_1764_mul_13\", tensor_type=DT_FLOAT, _device=\"/job:localhost/replica:0/task:0/cpu:0\"]()]]\n\nCaused by op u'mul_109', defined at:\n  File \"/usr/lib64/python2.7/runpy.py\", line 162, in _run_module_as_main\n    \"__main__\", fname, loader, pkg_name)\n  File \"/usr/lib64/python2.7/runpy.py\", line 72, in _run_code\n    exec code in run_globals\n  File \"/t1-home/molimm2/dwaithe/.local/lib/python2.7/site-packages/ipykernel/__main__.py\", line 3, in <module>\n    app.launch_new_instance()\n  File \"/home/molimm2/dwaithe/.local/lib/python2.7/site-packages/traitlets/config/application.py\", line 658, in launch_instance\n    app.start()\n  File \"/home/molimm2/dwaithe/.local/lib/python2.7/site-packages/ipykernel/kernelapp.py\", line 474, in start\n    ioloop.IOLoop.instance().start()\n  File \"/home/molimm2/dwaithe/.local/lib/python2.7/site-packages/zmq/eventloop/ioloop.py\", line 177, in start\n    super(ZMQIOLoop, self).start()\n  File \"/home/molimm2/dwaithe/.local/lib/python2.7/site-packages/tornado/ioloop.py\", line 887, in start\n    handler_func(fd_obj, events)\n  File \"/home/molimm2/dwaithe/.local/lib/python2.7/site-packages/tornado/stack_context.py\", line 275, in null_wrapper\n    return fn(*args, **kwargs)\n  File \"/home/molimm2/dwaithe/.local/lib/python2.7/site-packages/zmq/eventloop/zmqstream.py\", line 440, in _handle_events\n    self._handle_recv()\n  File \"/home/molimm2/dwaithe/.local/lib/python2.7/site-packages/zmq/eventloop/zmqstream.py\", line 472, in _handle_recv\n    self._run_callback(callback, msg)\n  File \"/home/molimm2/dwaithe/.local/lib/python2.7/site-packages/zmq/eventloop/zmqstream.py\", line 414, in _run_callback\n    callback(*args, **kwargs)\n  File \"/home/molimm2/dwaithe/.local/lib/python2.7/site-packages/tornado/stack_context.py\", line 275, in null_wrapper\n    return fn(*args, **kwargs)\n  File \"/home/molimm2/dwaithe/.local/lib/python2.7/site-packages/ipykernel/kernelbase.py\", line 276, in dispatcher\n    return self.dispatch_shell(stream, msg)\n  File \"/home/molimm2/dwaithe/.local/lib/python2.7/site-packages/ipykernel/kernelbase.py\", line 228, in dispatch_shell\n    handler(stream, idents, msg)\n  File \"/home/molimm2/dwaithe/.local/lib/python2.7/site-packages/ipykernel/kernelbase.py\", line 390, in execute_request\n    user_expressions, allow_stdin)\n  File \"/home/molimm2/dwaithe/.local/lib/python2.7/site-packages/ipykernel/ipkernel.py\", line 196, in do_execute\n    res = shell.run_cell(code, store_history=store_history, silent=silent)\n  File \"/home/molimm2/dwaithe/.local/lib/python2.7/site-packages/ipykernel/zmqshell.py\", line 501, in run_cell\n    return super(ZMQInteractiveShell, self).run_cell(*args, **kwargs)\n  File \"/home/molimm2/dwaithe/.local/lib/python2.7/site-packages/IPython/core/interactiveshell.py\", line 2717, in run_cell\n    interactivity=interactivity, compiler=compiler, result=result)\n  File \"/home/molimm2/dwaithe/.local/lib/python2.7/site-packages/IPython/core/interactiveshell.py\", line 2821, in run_ast_nodes\n    if self.run_code(code, result):\n  File \"/home/molimm2/dwaithe/.local/lib/python2.7/site-packages/IPython/core/interactiveshell.py\", line 2881, in run_code\n    exec(code_obj, self.user_global_ns, self.user_ns)\n  File \"<ipython-input-57-67f2c0cccadb>\", line 1, in <module>\n    results = cnn.fit(X, y, nb_epoch=200, batch_size=100,verbose=0)\n  File \"/home/molimm2/dwaithe/.local/lib/python2.7/site-packages/keras/models.py\", line 664, in fit\n    sample_weight=sample_weight)\n  File \"/home/molimm2/dwaithe/.local/lib/python2.7/site-packages/keras/engine/training.py\", line 1115, in fit\n    self._make_train_function()\n  File \"/home/molimm2/dwaithe/.local/lib/python2.7/site-packages/keras/engine/training.py\", line 713, in _make_train_function\n    self.total_loss)\n  File \"/home/molimm2/dwaithe/.local/lib/python2.7/site-packages/keras/optimizers.py\", line 392, in get_updates\n    v_t = (self.beta_2 * v) + (1. - self.beta_2) * K.square(g)\n  File \"/home/molimm2/dwaithe/.local/lib/python2.7/site-packages/tensorflow/python/ops/variables.py\", line 690, in _run_op\n    return getattr(ops.Tensor, operator)(a._AsTensor(), *args)\n  File \"/home/molimm2/dwaithe/.local/lib/python2.7/site-packages/tensorflow/python/ops/math_ops.py\", line 814, in binary_op_wrapper\n    return func(x, y, name=name)\n  File \"/home/molimm2/dwaithe/.local/lib/python2.7/site-packages/tensorflow/python/ops/math_ops.py\", line 987, in _mul_dispatch\n    return gen_math_ops.mul(x, y, name=name)\n  File \"/home/molimm2/dwaithe/.local/lib/python2.7/site-packages/tensorflow/python/ops/gen_math_ops.py\", line 1613, in mul\n    result = _op_def_lib.apply_op(\"Mul\", x=x, y=y, name=name)\n  File \"/home/molimm2/dwaithe/.local/lib/python2.7/site-packages/tensorflow/python/framework/op_def_library.py\", line 759, in apply_op\n    op_def=op_def)\n  File \"/home/molimm2/dwaithe/.local/lib/python2.7/site-packages/tensorflow/python/framework/ops.py\", line 2240, in create_op\n    original_op=self._default_original_op, op_def=op_def)\n  File \"/home/molimm2/dwaithe/.local/lib/python2.7/site-packages/tensorflow/python/framework/ops.py\", line 1128, in __init__\n    self._traceback = _extract_stack()\n\nResourceExhaustedError (see above for traceback): OOM when allocating tensor with shape[8192,1024]\n\t [[Node: mul_109 = Mul[T=DT_FLOAT, _device=\"/job:localhost/replica:0/task:0/gpu:0\"](Variable_13/read, Variable_53/read)]]\n\t [[Node: mul_13/_135 = _Recv[client_terminated=false, recv_device=\"/job:localhost/replica:0/task:0/cpu:0\", send_device=\"/job:localhost/replica:0/task:0/gpu:0\", send_device_incarnation=1, tensor_name=\"edge_1764_mul_13\", tensor_type=DT_FLOAT, _device=\"/job:localhost/replica:0/task:0/cpu:0\"]()]]\n"
     ]
    }
   ],
   "source": [
    "results = cnn.fit(X, y, nb_epoch=200, batch_size=100,verbose=0) \n",
    "    #Evaluation code which makes prediction\n",
    "#out = cnn.predict(test_dt.reshape((N_test_cell, Int_profile_len,1, 1)))    \n",
    "    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 49,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[[ 0.05020747  0.05020747  0.05020747 ...,  0.13838174  0.14170124\n",
      "   0.14232365]\n",
      " [ 0.02694195  0.02640405  0.01496613 ...,  0.11514694  0.11206235\n",
      "   0.11382382]\n",
      " [ 0.01012264  0.00966319  0.00981277 ...,  0.09845679  0.09768519\n",
      "   0.09880401]\n",
      " ..., \n",
      " [ 0.05020747  0.05020747  0.05020747 ...,  0.11037344  0.11224066\n",
      "   0.1126556 ]\n",
      " [ 0.06607738  0.06652216  0.05298775 ...,  0.1419727   0.14031126\n",
      "   0.14080822]\n",
      " [ 0.01187227  0.01231665  0.00994663 ...,  0.14610626  0.14046579\n",
      "   0.13901019]]\n",
      "[1 1 2 ..., 1 2 1]\n"
     ]
    }
   ],
   "source": [
    "print(test_dt)\n",
    "print(test_cl)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 50,
   "metadata": {
    "collapsed": false,
    "deletable": true,
    "editable": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(1180, 6)\n",
      "[1 1 2 ..., 1 2 1]\n",
      "99.406779661\n"
     ]
    }
   ],
   "source": [
    "# estimate accuracy on whole dataset using loaded weights\n",
    "out = cnn.predict(test_dt.reshape((N_test_cell, Int_profile_len,1, 1)))  \n",
    "\n",
    "print(out.shape)\n",
    "print(np.argmax(out,1))\n",
    "print((float(np.sum(np.argmax(out,1)==test_cl))/float(test_cl.shape[0])*100.0))"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 2",
   "language": "python",
   "name": "python2"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 2
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython2",
   "version": "2.7.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
